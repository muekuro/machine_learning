{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b11ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットをロード\n",
    "import numpy as np\n",
    "\n",
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
    "\n",
    "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "y_train[y_train == -1] = 0\n",
    "y_test[y_test == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを構築\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12348cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719acb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 500, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_32 (Multi  (None, 500, 1)      526         ['input_9[0][0]',                \n",
      " HeadAttention)                                                   'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 500, 1)       0           ['multi_head_attention_32[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_64 (LayerN  (None, 500, 1)      2           ['dropout_72[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_64 (TFOpL  (None, 500, 1)      0           ['layer_normalization_64[0][0]', \n",
      " ambda)                                                           'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_64 (Conv1D)             (None, 500, 4)       8           ['tf.__operators__.add_64[0][0]']\n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)           (None, 500, 4)       0           ['conv1d_64[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_65 (Conv1D)             (None, 500, 1)       5           ['dropout_73[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_65 (LayerN  (None, 500, 1)      2           ['conv1d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_65 (TFOpL  (None, 500, 1)      0           ['layer_normalization_65[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_64[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_33 (Multi  (None, 500, 1)      526         ['tf.__operators__.add_65[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_65[0][0]']\n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 500, 1)       0           ['multi_head_attention_33[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_66 (LayerN  (None, 500, 1)      2           ['dropout_74[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_66 (TFOpL  (None, 500, 1)      0           ['layer_normalization_66[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_65[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_66 (Conv1D)             (None, 500, 4)       8           ['tf.__operators__.add_66[0][0]']\n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 500, 4)       0           ['conv1d_66[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_67 (Conv1D)             (None, 500, 1)       5           ['dropout_75[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_67 (LayerN  (None, 500, 1)      2           ['conv1d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_67 (TFOpL  (None, 500, 1)      0           ['layer_normalization_67[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_66[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_34 (Multi  (None, 500, 1)      526         ['tf.__operators__.add_67[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_67[0][0]']\n",
      "                                                                                                  \n",
      " dropout_76 (Dropout)           (None, 500, 1)       0           ['multi_head_attention_34[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_68 (LayerN  (None, 500, 1)      2           ['dropout_76[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_68 (TFOpL  (None, 500, 1)      0           ['layer_normalization_68[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_67[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_68 (Conv1D)             (None, 500, 4)       8           ['tf.__operators__.add_68[0][0]']\n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 500, 4)       0           ['conv1d_68[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_69 (Conv1D)             (None, 500, 1)       5           ['dropout_77[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_69 (LayerN  (None, 500, 1)      2           ['conv1d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_69 (TFOpL  (None, 500, 1)      0           ['layer_normalization_69[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_68[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_35 (Multi  (None, 500, 1)      526         ['tf.__operators__.add_69[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_69[0][0]']\n",
      "                                                                                                  \n",
      " dropout_78 (Dropout)           (None, 500, 1)       0           ['multi_head_attention_35[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_70 (LayerN  (None, 500, 1)      2           ['dropout_78[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_70 (TFOpL  (None, 500, 1)      0           ['layer_normalization_70[0][0]', \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ambda)                                                           'tf.__operators__.add_69[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_70 (Conv1D)             (None, 500, 4)       8           ['tf.__operators__.add_70[0][0]']\n",
      "                                                                                                  \n",
      " dropout_79 (Dropout)           (None, 500, 4)       0           ['conv1d_70[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_71 (Conv1D)             (None, 500, 1)       5           ['dropout_79[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_71 (LayerN  (None, 500, 1)      2           ['conv1d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_71 (TFOpL  (None, 500, 1)      0           ['layer_normalization_71[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_70[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 500)         0           ['tf.__operators__.add_71[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          64128       ['global_average_pooling1d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)           (None, 128)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 2)            258         ['dropout_80[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66,558\n",
      "Trainable params: 66,558\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "45/45 [==============================] - 106s 2s/step - loss: 1.0255 - sparse_categorical_accuracy: 0.5170 - val_loss: 0.7676 - val_sparse_categorical_accuracy: 0.5589\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.8214 - sparse_categorical_accuracy: 0.5806 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.6144\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.7721 - sparse_categorical_accuracy: 0.5990 - val_loss: 0.6498 - val_sparse_categorical_accuracy: 0.6227\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.7158 - sparse_categorical_accuracy: 0.6299 - val_loss: 0.6247 - val_sparse_categorical_accuracy: 0.6408\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.6878 - sparse_categorical_accuracy: 0.6406 - val_loss: 0.6102 - val_sparse_categorical_accuracy: 0.6588\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6618 - val_loss: 0.5922 - val_sparse_categorical_accuracy: 0.6644\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.6264 - sparse_categorical_accuracy: 0.6740 - val_loss: 0.5800 - val_sparse_categorical_accuracy: 0.6727\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.5994 - sparse_categorical_accuracy: 0.6986 - val_loss: 0.5692 - val_sparse_categorical_accuracy: 0.6824\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.5948 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.5631 - val_sparse_categorical_accuracy: 0.7004\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.5690 - sparse_categorical_accuracy: 0.7097 - val_loss: 0.5556 - val_sparse_categorical_accuracy: 0.7046\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.5557 - sparse_categorical_accuracy: 0.7188 - val_loss: 0.5471 - val_sparse_categorical_accuracy: 0.7087\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.5585 - sparse_categorical_accuracy: 0.7208 - val_loss: 0.5402 - val_sparse_categorical_accuracy: 0.7101\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.5240 - sparse_categorical_accuracy: 0.7396 - val_loss: 0.5341 - val_sparse_categorical_accuracy: 0.7171\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 135s 3s/step - loss: 0.5247 - sparse_categorical_accuracy: 0.7479 - val_loss: 0.5271 - val_sparse_categorical_accuracy: 0.7226\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.4978 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.5234 - val_sparse_categorical_accuracy: 0.7268\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.4987 - sparse_categorical_accuracy: 0.7521 - val_loss: 0.5159 - val_sparse_categorical_accuracy: 0.7434\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.4762 - sparse_categorical_accuracy: 0.7722 - val_loss: 0.5112 - val_sparse_categorical_accuracy: 0.7476\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.4794 - sparse_categorical_accuracy: 0.7743 - val_loss: 0.5089 - val_sparse_categorical_accuracy: 0.7517\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.4703 - sparse_categorical_accuracy: 0.7774 - val_loss: 0.5020 - val_sparse_categorical_accuracy: 0.7601\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.4528 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.4981 - val_sparse_categorical_accuracy: 0.7670\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.4498 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.4928 - val_sparse_categorical_accuracy: 0.7684\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.4645 - sparse_categorical_accuracy: 0.7799 - val_loss: 0.4889 - val_sparse_categorical_accuracy: 0.7739\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.4459 - sparse_categorical_accuracy: 0.7913 - val_loss: 0.4855 - val_sparse_categorical_accuracy: 0.7781\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 105s 2s/step - loss: 0.4305 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.4825 - val_sparse_categorical_accuracy: 0.7795\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 104s 2s/step - loss: 0.4178 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.4784 - val_sparse_categorical_accuracy: 0.7836\n",
      "Epoch 26/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.4171 - sparse_categorical_accuracy: 0.8174 - val_loss: 0.4740 - val_sparse_categorical_accuracy: 0.7809\n",
      "Epoch 27/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.4019 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.4700 - val_sparse_categorical_accuracy: 0.7906\n",
      "Epoch 28/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.4031 - sparse_categorical_accuracy: 0.8260 - val_loss: 0.4658 - val_sparse_categorical_accuracy: 0.7906\n",
      "Epoch 29/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3957 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.4617 - val_sparse_categorical_accuracy: 0.7920\n",
      "Epoch 30/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3913 - sparse_categorical_accuracy: 0.8285 - val_loss: 0.4602 - val_sparse_categorical_accuracy: 0.7906\n",
      "Epoch 31/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3717 - sparse_categorical_accuracy: 0.8399 - val_loss: 0.4576 - val_sparse_categorical_accuracy: 0.7920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3708 - sparse_categorical_accuracy: 0.8396 - val_loss: 0.4527 - val_sparse_categorical_accuracy: 0.7947\n",
      "Epoch 33/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3662 - sparse_categorical_accuracy: 0.8462 - val_loss: 0.4505 - val_sparse_categorical_accuracy: 0.7947\n",
      "Epoch 34/200\n",
      "45/45 [==============================] - 1215s 28s/step - loss: 0.3609 - sparse_categorical_accuracy: 0.8476 - val_loss: 0.4480 - val_sparse_categorical_accuracy: 0.7975\n",
      "Epoch 35/200\n",
      "45/45 [==============================] - 102s 2s/step - loss: 0.3511 - sparse_categorical_accuracy: 0.8562 - val_loss: 0.4451 - val_sparse_categorical_accuracy: 0.8114\n",
      "Epoch 36/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3481 - sparse_categorical_accuracy: 0.8569 - val_loss: 0.4434 - val_sparse_categorical_accuracy: 0.8003\n",
      "Epoch 37/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3456 - sparse_categorical_accuracy: 0.8531 - val_loss: 0.4395 - val_sparse_categorical_accuracy: 0.8017\n",
      "Epoch 38/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3482 - sparse_categorical_accuracy: 0.8556 - val_loss: 0.4374 - val_sparse_categorical_accuracy: 0.8003\n",
      "Epoch 39/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3366 - sparse_categorical_accuracy: 0.8608 - val_loss: 0.4342 - val_sparse_categorical_accuracy: 0.7989\n",
      "Epoch 40/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3355 - sparse_categorical_accuracy: 0.8674 - val_loss: 0.4320 - val_sparse_categorical_accuracy: 0.8031\n",
      "Epoch 41/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3302 - sparse_categorical_accuracy: 0.8632 - val_loss: 0.4330 - val_sparse_categorical_accuracy: 0.8044\n",
      "Epoch 42/200\n",
      "45/45 [==============================] - 103s 2s/step - loss: 0.3250 - sparse_categorical_accuracy: 0.8681 - val_loss: 0.4280 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 43/200\n",
      "45/45 [==============================] - 1031s 23s/step - loss: 0.3206 - sparse_categorical_accuracy: 0.8788 - val_loss: 0.4267 - val_sparse_categorical_accuracy: 0.8031\n",
      "Epoch 44/200\n",
      "45/45 [==============================] - 1742s 40s/step - loss: 0.3230 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.4222 - val_sparse_categorical_accuracy: 0.8128\n",
      "Epoch 45/200\n",
      "45/45 [==============================] - 102s 2s/step - loss: 0.3117 - sparse_categorical_accuracy: 0.8823 - val_loss: 0.4209 - val_sparse_categorical_accuracy: 0.8086\n",
      "Epoch 46/200\n",
      "21/45 [=============>................] - ETA: 50s - loss: 0.3159 - sparse_categorical_accuracy: 0.8795"
     ]
    }
   ],
   "source": [
    "# トレーニングと評価\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=25, # 256から減らした(永遠に終わらない)\n",
    "    num_heads=3, # 4 -> 3\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac5848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
